import torch
import torch.nn as nn
import torch.nn.functional as F
import math


# ===========================
# ğŸ§­ åœ°ç†ä½ç½®ç¼–ç ï¼ˆGeoPosEncodingï¼‰
# ===========================
class GeoPosEncoding(nn.Module):
    """
    äºŒç»´ç»çº¬åº¦ä½ç½®ç¼–ç ï¼Œç”¨äºç©ºé—´æ³¨æ„åŠ›ã€‚
    å¯é€‰ï¼šé€šè¿‡è·ç¦»çŸ©é˜µæˆ–æ ¼ç‚¹ç´¢å¼•ç”Ÿæˆã€‚
    """
    def __init__(self, embed_dim, height=8, width=8):
        super(GeoPosEncoding, self).__init__()
        self.embed_dim = embed_dim
        self.height = height
        self.width = width

        # æ­£å¼¦ä½ç½®ç¼–ç ï¼ˆå¯ç”¨äºè§„åˆ™ç½‘æ ¼ï¼‰
        pe = torch.zeros(height * width, embed_dim)
        position = torch.arange(0, height * width, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        self.register_buffer('pe', pe.unsqueeze(0))  # [1, H*W, D]

    def forward(self, B):
        return self.pe.repeat(B, 1, 1)  # [B, H*W, D]


# ===========================
# ğŸŒ ç©ºé—´å›¾å·ç§¯å±‚ï¼ˆGraphConvï¼‰
# ===========================
class GraphConv(nn.Module):
    """
    åŸºäºé‚»æ¥çŸ©é˜µçš„å›¾å·ç§¯å±‚
    """
    def __init__(self, in_dim, out_dim, bias=True):
        super(GraphConv, self).__init__()
        self.fc = nn.Linear(in_dim, out_dim, bias=bias)

    def forward(self, x, adj):
        # x: [B, N, D], adj: [N, N]
        support = self.fc(x)
        out = torch.bmm(adj.unsqueeze(0).expand(x.size(0), -1, -1), support)
        return out


# ===========================
# ğŸ§  ç©ºé—´è‡ªæ³¨æ„åŠ›æ¨¡å—ï¼ˆæ ¸å¿ƒåˆ›æ–°ï¼‰
# ===========================
class SpatialSelfAttention(nn.Module):
    """
    å¤šå¤´ç©ºé—´æ³¨æ„åŠ› + å›¾å·ç§¯å¢å¼ºã€‚
    æ”¯æŒå¯é€‰åœ°ç†æ©ç  (geo_mask) å’Œè¯­ä¹‰æ©ç  (sem_mask)
    """
    def __init__(self, embed_dim=64, n_heads=4, mem_window=5,
                 dropout=0.1, use_geo=True, use_sem=True, use_gcn=True):
        super(SpatialSelfAttention, self).__init__()
        self.embed_dim = embed_dim
        self.n_heads = n_heads
        self.d_k = embed_dim // n_heads
        self.dropout = nn.Dropout(dropout)
        self.use_geo = use_geo
        self.use_sem = use_sem
        self.use_gcn = use_gcn

        # å¤šå¤´æŠ•å½±
        self.query = nn.Linear(embed_dim, embed_dim)
        self.key = nn.Linear(embed_dim, embed_dim)
        self.value = nn.Linear(embed_dim, embed_dim)

        # å›¾å·ç§¯å±‚ï¼ˆå¯é€‰ï¼‰
        if use_gcn:
            self.gcn = GraphConv(embed_dim, embed_dim)

        # åœ°ç†ä½ç½®ç¼–ç 
        if use_geo:
            self.geo_encoding = GeoPosEncoding(embed_dim, height=8, width=8)

        # è¾“å‡ºå±‚
        self.out_proj = nn.Linear(embed_dim, embed_dim)

    def forward(self, x, geo_mask=None, sem_mask=None):
        """
        x: [B, C, Nt, Ps, D]
        geo_mask, sem_mask: [N, N] é‚»æ¥çŸ©é˜µæˆ–æ©ç 
        """
        B, C, Nt, Ps, D = x.shape
        x = x.view(B, -1, D)  # [B, N, D], N = C*Nt*Ps

        # === åŠ å…¥åœ°ç†ä½ç½®ç¼–ç  ===
        if self.use_geo:
            pos_enc = self.geo_encoding(B)
            if pos_enc.size(1) != x.size(1):
                pos_enc = F.interpolate(pos_enc.transpose(1, 2), size=x.size(1), mode='linear').transpose(1, 2)
            x = x + pos_enc

        # === è®¡ç®—æ³¨æ„åŠ›æƒé‡ ===
        Q = self.query(x).view(B, -1, self.n_heads, self.d_k).transpose(1, 2)
        K = self.key(x).view(B, -1, self.n_heads, self.d_k).transpose(1, 2)
        V = self.value(x).view(B, -1, self.n_heads, self.d_k).transpose(1, 2)

        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)  # [B, H, N, N]

        # === åŠ å…¥æ©ç  ===
        if geo_mask is not None:
            scores = scores.masked_fill(geo_mask == 0, -1e9)
        if sem_mask is not None:
            scores = scores.masked_fill(sem_mask == 0, -1e9)

        attn = F.softmax(scores, dim=-1)
        attn = self.dropout(attn)

        out = torch.matmul(attn, V)  # [B, H, N, d_k]
        out = out.transpose(1, 2).contiguous().view(B, -1, self.embed_dim)

        # === å›¾å·ç§¯å¢å¼º ===
        if self.use_gcn:
            # ç®€å•æ„é€ é‚»æ¥çŸ©é˜µï¼šå®Œå…¨å›¾æˆ–æ©ç å›¾
            if geo_mask is not None:
                adj = geo_mask.float()
            else:
                adj = torch.ones(x.size(1), x.size(1), device=x.device)
            out = out + self.gcn(out, adj)

        out = self.out_proj(out)
        out = out.view(B, C, Nt, Ps, D)
        return out


# ===========================
# âœ… æ¨¡å—æµ‹è¯•ï¼ˆç‹¬ç«‹å¯è¿è¡Œï¼‰
# ===========================
if __name__ == "__main__":
    B, C, Nt, Ps, D = 2, 1, 6, 8, 64
    x = torch.randn(B, C, Nt, Ps, D)
    spa = SpatialSelfAttention(embed_dim=64, n_heads=4, use_geo=True, use_gcn=True)
    out = spa(x)
    print("Input:", x.shape)
    print("Output:", out.shape)
